#!/usr/bin/env -S node --enable-source-maps

import * as path from 'path';
import * as url from 'url';
import { writeFileSync } from 'fs';
import { join } from 'path';
import OpenAI from 'openai';

import 'dotenv/config.js';

import type { NavLink } from 'docs/server/navigation.tsx';
import navigation from 'docs/server/navigation.tsx';
import { renderDown } from 'docs/server/SSRPage.tsx';
import Env from 'server/src/config/Env.ts';
import parseDownToPlaintextStrings from 'docs/lib/parseDownToPlaintext.ts';
import type { DocsCachedEmbedding } from 'common/types/index.ts';

// This script will run the server-side rendering logic for every non-hidden
// page in the docs navigation file. It takes that rendered HTML and creates
// an OpenAI "embedding" (https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)
// which can be used to compute search results. These embeddings are
// dumped into a generated TS file and used by the docs server to do
// pretty respectable searching over our docs.
//
// It works by doing two important steps:
//   - First, it renders every page of our docs down to plaintext
//   - Second, it computes an OpenAI "embedding" for each of those
//     plaintexts
//
// Both of those get written to a plain old JavaScript object.
//
// The SearchAPI endpoint loads those objects, accepts search queries, computes
// the embedding vector for the search query, then iterates over the
// pre-computed embeddings, figuring out which plaintext page was the most
// similar the search query. That endpoint returns the ranked pages, the
// plaintext, and the URL.

const MAX_EMBEDDING_TEXT_LENGTH = 20000;

const openai = new OpenAI({
  apiKey: Env.OPENAI_API_SECRET,
});

async function createEmbedding(input: string) {
  const { data, response } = await openai.embeddings
    .create({
      model: 'text-embedding-ada-002',
      input,
    })
    .withResponse();
  if (response.status !== 200) {
    console.error(response.statusText);
  }
  return data;
}

const main = async () => {
  const pages: { [url: string]: string } = {};

  function recursiveRender(subnav: NavLink[]) {
    for (const item of subnav) {
      if (item.hidden || item.linkTo.startsWith('http')) {
        continue;
      }

      pages[item.linkTo] = renderDown({
        path: item.linkTo,
        embeddingMode: true,
      });
      if (item.subnav) {
        recursiveRender(item.subnav);
      }
    }
  }

  recursiveRender(navigation);

  const embeddings: DocsCachedEmbedding[] = [];
  const promises: Array<Promise<void>> = [];
  for (const pageUrl in pages) {
    const page = pages[pageUrl];
    const txts = parseDownToPlaintextStrings(page);
    let timeoutLength = 0;
    for (const plaintext of txts) {
      const embedding: DocsCachedEmbedding = {
        url: pageUrl,
        embedding: undefined,
        plaintext,
      };
      embeddings.push(embedding);
      promises.push(
        // All of this is because OpenAI seems to apply random throttling / API request caps.
        // We have to slow down our rate of calls otherwise it fails randomly.
        new Promise((res) => {
          setTimeout(
            // eslint-disable-next-line @typescript-eslint/no-misused-promises -- Disabling for pre-existing problems. Please do not copy this comment, and consider fixing this one!
            async () => {
              if (plaintext.length > MAX_EMBEDDING_TEXT_LENGTH) {
                console.error(
                  'Truncating very long plaintext chunk for page: ' + pageUrl,
                );
                console.error('Plaintext chunk is: ' + plaintext);
                process.exit(1);
              }
              console.log('Creating an embedding for ' + pageUrl);
              try {
                const data = await createEmbedding(plaintext);
                embedding.embedding = data;
                res();
              } catch (e) {
                console.error(
                  'Failed to fetch embedding for chunk: ' + plaintext,
                );
                console.error(e);
                process.exit(1);
              }
            },
            (timeoutLength += 100),
          );
        }),
      );
    }
  }

  await Promise.all(promises);

  const embeddingsFile = `// @generated by scripts/docs-generate-search-data.ts
import type { DocsCachedEmbedding } from 'common/types/index.ts';

const embeddings: DocsCachedEmbedding[] = ${JSON.stringify(
    embeddings,
    null,
    2,
  )};

export default embeddings;\n`;
  writeFileSync(
    join(
      path.dirname(url.fileURLToPath(import.meta.url)),
      '../../docs/server/searchData/Embeddings.ts',
    ),
    embeddingsFile,
  );
};

Promise.resolve(main()).catch((err) => {
  console.error(err);
  process.exit(1);
});
